{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chibu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "########## 1. Import required libraries ##########\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "\n",
    "# Text and feature engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Evaluation and tuning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_curve, auc, classification_report)\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Text cleaning & stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Preprocess and Save Processed Data to CSV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 2. Define text preprocessing methods ##########\n",
    "\n",
    "def remove_html(text):\n",
    "    \"\"\"Remove HTML tags using a regex.\"\"\"\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'', text)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    \"\"\"Remove emojis using a regex pattern.\"\"\"\n",
    "    emoji_pattern = re.compile(\"[\" u\"\\U0001F600-\\U0001F64F\"  \n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                               u\"\\U00002702-\\U000027B0\"  \n",
    "                               u\"\\U000024C2-\\U0001F251\" \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    custom_stopwords = {}  # Define your custom stopwords here\n",
    "    stop_words.update(custom_stopwords)\n",
    "    return \" \".join([word for word in text.split() if word.lower() not in stop_words])\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Clean text by removing non-alphanumeric characters,\n",
    "    and convert it to lowercase.\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),.!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"\\)\", \" ) \", string)\n",
    "    string = re.sub(r\"\\?\", \" ? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = re.sub(r\"\\\\\", \"\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)\n",
    "    string = re.sub(r\"\\\"\", \"\", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "def check_data_leakage(X_train, X_test):\n",
    "    train_set = set(map(tuple, X_train))\n",
    "    test_set = set(map(tuple, X_test))\n",
    "\n",
    "    leaked_samples = train_set.intersection(test_set)\n",
    "    print(\"\\nüîç Checking Data Leakage...\")\n",
    "    print(f\"‚ö†Ô∏è {len(leaked_samples)} samples from test data are also in training data.\")\n",
    "\n",
    "    if len(leaked_samples) > 0:\n",
    "        print(\"‚ùå Data Leakage Detected! Test data should not exist in training set.\")\n",
    "    else:\n",
    "        print(\"‚úÖ No Data Leakage Detected.\")\n",
    "\n",
    "##COMAPRES TEST ACCURACY TO TRAIN ACCURACY\n",
    "def check_overfitting(model, X_train, y_train, X_test, y_test):\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    train_acc = accuracy_score(y_train, train_preds)\n",
    "    test_acc = accuracy_score(y_test, test_preds)\n",
    "    \n",
    "    print(\"\\nüîç Checking Overfitting...\")\n",
    "    print(f\"üìä Training Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"üìä Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    if train_acc > test_acc + 0.10:\n",
    "        print(\"‚ùå Possible Overfitting: Model performs much better on training data.\")\n",
    "    else:\n",
    "        print(\"‚úÖ No significant overfitting detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download and read data, save to csv files for repeatable use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 3. Download & read data ##########\n",
    "project = 'tensorflow'\n",
    "text_col = 'Title+Body'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'C:/Users/chibu/Documents/ISE-solution-main/Coursework/datasets/{project}.csv'\n",
    "\n",
    "data = pd.read_csv(path).fillna('')\n",
    "data['Title+Body'] = data.apply(lambda row: row['Title'] + '. ' + row['Body'] if pd.notna(row['Body']) else row['Title'], axis=1)\n",
    "#text_col = 'Title+Body'\n",
    "\n",
    "data[text_col] = data[text_col].apply(remove_html)\n",
    "data[text_col] = data[text_col].apply(remove_emoji)\n",
    "data[text_col] = data[text_col].apply(remove_stopwords)\n",
    "data[text_col] = data[text_col].apply(clean_str)\n",
    "\n",
    "data.to_csv(f'{project}_processed_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and check datasets in Title+Body Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Repository</th>\n",
       "      <th>Number</th>\n",
       "      <th>State</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Codes</th>\n",
       "      <th>Commands</th>\n",
       "      <th>class</th>\n",
       "      <th>related</th>\n",
       "      <th>Title+Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>8704</td>\n",
       "      <td>closed</td>\n",
       "      <td>TensorFlow drops the first batch?</td>\n",
       "      <td>### Description\\r\\n\\r\\nI'm trying to understan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['More logging output. You can see that there ...</td>\n",
       "      <td>[\"\\r\\n'image/id': tf.FixedLenFeature(shape=[],...</td>\n",
       "      <td>['TFRecord', 'image/id', 'TFRecord', 'num_samp...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tensorflow drops first batch ? . description t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>10245</td>\n",
       "      <td>closed</td>\n",
       "      <td>Implement Focused Online Learning which conver...</td>\n",
       "      <td>![image](https://cloud.githubusercontent.com/a...</td>\n",
       "      <td>stat:awaiting response type:feature</td>\n",
       "      <td>['Thoughts on this feature request @fchollet?'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>implement focused online learning converges fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>27143</td>\n",
       "      <td>closed</td>\n",
       "      <td>[TF 2.0] tf 2 around 40 times slower than tf 1...</td>\n",
       "      <td>**System information**\\r\\n- Have I written cus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Ah!\\r\\n\\r\\nThis is the subtlest and most com...</td>\n",
       "      <td>['shell\\r\\n(tf1) $ python expm.py \\r\\nBENCHMAR...</td>\n",
       "      <td>['expm', 'taylor_v2', '_pywrap_tensorflow_inte...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tf 2.0 tf 2 around 40 times slower tf 1 unroll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>12808</td>\n",
       "      <td>closed</td>\n",
       "      <td>tensorflow performance issue for map_fn and ga...</td>\n",
       "      <td>I am trying to understand more about certain s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['This question is better asked on  [StackOver...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['map_fn', 'tree_offset_tensor', 'map_fn', 'ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tensorflow performance issue map fn gather. tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>23049</td>\n",
       "      <td>open</td>\n",
       "      <td>Ghost Batch Normalization performance</td>\n",
       "      <td>GBN seems to be at least twice as slow as regu...</td>\n",
       "      <td>comp:keras comp:model stat:awaiting tensorflower</td>\n",
       "      <td>['Thank you for your post. We noticed you have...</td>\n",
       "      <td>['bash\\r\\n\\r\\ngit clone git@github.com:tensorf...</td>\n",
       "      <td>['virtual_batch_size=batch_size']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ghost batch normalization performance. gbn see...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Repository  Number   State  \\\n",
       "0           0  tensorflow    8704  closed   \n",
       "1           1  tensorflow   10245  closed   \n",
       "2           2  tensorflow   27143  closed   \n",
       "3           3  tensorflow   12808  closed   \n",
       "4           4  tensorflow   23049    open   \n",
       "\n",
       "                                               Title  \\\n",
       "0                  TensorFlow drops the first batch?   \n",
       "1  Implement Focused Online Learning which conver...   \n",
       "2  [TF 2.0] tf 2 around 40 times slower than tf 1...   \n",
       "3  tensorflow performance issue for map_fn and ga...   \n",
       "4              Ghost Batch Normalization performance   \n",
       "\n",
       "                                                Body  \\\n",
       "0  ### Description\\r\\n\\r\\nI'm trying to understan...   \n",
       "1  ![image](https://cloud.githubusercontent.com/a...   \n",
       "2  **System information**\\r\\n- Have I written cus...   \n",
       "3  I am trying to understand more about certain s...   \n",
       "4  GBN seems to be at least twice as slow as regu...   \n",
       "\n",
       "                                             Labels  \\\n",
       "0                                               NaN   \n",
       "1               stat:awaiting response type:feature   \n",
       "2                                               NaN   \n",
       "3                                               NaN   \n",
       "4  comp:keras comp:model stat:awaiting tensorflower   \n",
       "\n",
       "                                            Comments  \\\n",
       "0  ['More logging output. You can see that there ...   \n",
       "1  ['Thoughts on this feature request @fchollet?'...   \n",
       "2  [\"Ah!\\r\\n\\r\\nThis is the subtlest and most com...   \n",
       "3  ['This question is better asked on  [StackOver...   \n",
       "4  ['Thank you for your post. We noticed you have...   \n",
       "\n",
       "                                               Codes  \\\n",
       "0  [\"\\r\\n'image/id': tf.FixedLenFeature(shape=[],...   \n",
       "1                                                 []   \n",
       "2  ['shell\\r\\n(tf1) $ python expm.py \\r\\nBENCHMAR...   \n",
       "3                                                 []   \n",
       "4  ['bash\\r\\n\\r\\ngit clone git@github.com:tensorf...   \n",
       "\n",
       "                                            Commands  class  related  \\\n",
       "0  ['TFRecord', 'image/id', 'TFRecord', 'num_samp...      1        0   \n",
       "1                                                 []      1        0   \n",
       "2  ['expm', 'taylor_v2', '_pywrap_tensorflow_inte...      1        0   \n",
       "3  ['map_fn', 'tree_offset_tensor', 'map_fn', 'ge...      1        0   \n",
       "4                  ['virtual_batch_size=batch_size']      1        0   \n",
       "\n",
       "                                          Title+Body  \n",
       "0  tensorflow drops first batch ? . description t...  \n",
       "1  implement focused online learning converges fa...  \n",
       "2  tf 2.0 tf 2 around 40 times slower tf 1 unroll...  \n",
       "3  tensorflow performance issue map fn gather. tr...  \n",
       "4  ghost batch normalization performance. gbn see...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_path = 'C:/Users/chibu/Documents/ISE-solution-main/Coursework/trial2'\n",
    "\n",
    "df = pd.read_csv(f'{project}_processed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Configure parameters and start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set values, params and load csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of repeated experiments\n",
    "REPEAT = 30\n",
    "\n",
    "# Output CSV file name\n",
    "results_dir = \"C:/Users/chibu/Documents/ISE-solution-main/Coursework/trial2/results\"\n",
    "out_csv_name = f\"{results_dir}/{project}_Results.csv\"\n",
    "\n",
    "# Convert and save metrics for all models\n",
    "def save_model_metrics(metrics_list, filename):\n",
    "    df = pd.DataFrame(metrics_list)\n",
    "    df.to_csv(f\"{results_dir}/{filename}\", index=False)\n",
    "    print(f\"Saved: {filename}\")\n",
    "    print(df.mean(numeric_only=True))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Hyperparameter grid for Naive Bayes\n",
    "params = {'var_smoothing': np.logspace(-12, 0, 13)}\n",
    "\n",
    "# Lists to store metrics across repeated runs\n",
    "accuracies, precisions, recalls, f1_scores, auc_values = [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform Testing on Baseline code from Lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       0.000000\n",
      "Accuracy     0.574944\n",
      "Precision    0.633698\n",
      "Recall       0.727817\n",
      "F1           0.548072\n",
      "AUC          0.727817\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       0.500000\n",
      "Accuracy     0.549217\n",
      "Precision    0.624247\n",
      "Recall       0.703996\n",
      "F1           0.527059\n",
      "AUC          0.703996\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       1.000000\n",
      "Accuracy     0.555556\n",
      "Precision    0.627254\n",
      "Recall       0.710437\n",
      "F1           0.532547\n",
      "AUC          0.710437\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       1.500000\n",
      "Accuracy     0.560962\n",
      "Precision    0.630200\n",
      "Recall       0.706944\n",
      "F1           0.540024\n",
      "AUC          0.706944\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       2.000000\n",
      "Accuracy     0.565548\n",
      "Precision    0.633954\n",
      "Recall       0.711273\n",
      "F1           0.545033\n",
      "AUC          0.711273\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       2.500000\n",
      "Accuracy     0.563758\n",
      "Precision    0.633484\n",
      "Recall       0.711846\n",
      "F1           0.543074\n",
      "AUC          0.711846\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       3.000000\n",
      "Accuracy     0.560562\n",
      "Precision    0.633724\n",
      "Recall       0.710632\n",
      "F1           0.540776\n",
      "AUC          0.710632\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       3.500000\n",
      "Accuracy     0.558166\n",
      "Precision    0.633131\n",
      "Recall       0.707848\n",
      "F1           0.539146\n",
      "AUC          0.707848\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       4.000000\n",
      "Accuracy     0.556798\n",
      "Precision    0.633474\n",
      "Recall       0.706988\n",
      "F1           0.538390\n",
      "AUC          0.706988\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       4.500000\n",
      "Accuracy     0.560626\n",
      "Precision    0.634966\n",
      "Recall       0.709986\n",
      "F1           0.541741\n",
      "AUC          0.709986\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       5.000000\n",
      "Accuracy     0.563148\n",
      "Precision    0.637059\n",
      "Recall       0.713247\n",
      "F1           0.544287\n",
      "AUC          0.713247\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       5.500000\n",
      "Accuracy     0.561148\n",
      "Precision    0.636553\n",
      "Recall       0.712445\n",
      "F1           0.542487\n",
      "AUC          0.712445\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       6.000000\n",
      "Accuracy     0.560317\n",
      "Precision    0.635479\n",
      "Recall       0.712117\n",
      "F1           0.541191\n",
      "AUC          0.712117\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       6.500000\n",
      "Accuracy     0.561042\n",
      "Precision    0.635598\n",
      "Recall       0.712104\n",
      "F1           0.541894\n",
      "AUC          0.712104\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       7.000000\n",
      "Accuracy     0.558837\n",
      "Precision    0.635039\n",
      "Recall       0.712541\n",
      "F1           0.539574\n",
      "AUC          0.712541\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       7.500000\n",
      "Accuracy     0.556907\n",
      "Precision    0.634214\n",
      "Recall       0.710581\n",
      "F1           0.537970\n",
      "AUC          0.710581\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       8.000000\n",
      "Accuracy     0.556784\n",
      "Precision    0.633805\n",
      "Recall       0.710907\n",
      "F1           0.537522\n",
      "AUC          0.710907\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       8.500000\n",
      "Accuracy     0.556798\n",
      "Precision    0.634895\n",
      "Recall       0.710953\n",
      "F1           0.538075\n",
      "AUC          0.710953\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       9.000000\n",
      "Accuracy     0.558342\n",
      "Precision    0.635336\n",
      "Recall       0.712082\n",
      "F1           0.539358\n",
      "AUC          0.712082\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       9.500000\n",
      "Accuracy     0.554810\n",
      "Precision    0.634252\n",
      "Recall       0.710587\n",
      "F1           0.536053\n",
      "AUC          0.710587\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       10.000000\n",
      "Accuracy      0.552892\n",
      "Precision     0.632928\n",
      "Recall        0.708672\n",
      "F1            0.534140\n",
      "AUC           0.708672\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       10.500000\n",
      "Accuracy      0.551759\n",
      "Precision     0.632322\n",
      "Recall        0.707720\n",
      "F1            0.533074\n",
      "AUC           0.707720\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       11.000000\n",
      "Accuracy      0.552184\n",
      "Precision     0.633233\n",
      "Recall        0.707795\n",
      "F1            0.533899\n",
      "AUC           0.707795\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       11.500000\n",
      "Accuracy      0.549870\n",
      "Precision     0.632427\n",
      "Recall        0.705628\n",
      "F1            0.532012\n",
      "AUC           0.705628\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       12.000000\n",
      "Accuracy      0.550425\n",
      "Precision     0.632054\n",
      "Recall        0.705612\n",
      "F1            0.532242\n",
      "AUC           0.705612\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       12.500000\n",
      "Accuracy      0.549733\n",
      "Precision     0.631989\n",
      "Recall        0.705120\n",
      "F1            0.531743\n",
      "AUC           0.705120\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       13.000000\n",
      "Accuracy      0.549258\n",
      "Precision     0.631612\n",
      "Recall        0.704904\n",
      "F1            0.531176\n",
      "AUC           0.704904\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       13.500000\n",
      "Accuracy      0.547379\n",
      "Precision     0.631512\n",
      "Recall        0.703768\n",
      "F1            0.529715\n",
      "AUC           0.703768\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       14.000000\n",
      "Accuracy      0.547636\n",
      "Precision     0.631320\n",
      "Recall        0.704209\n",
      "F1            0.529702\n",
      "AUC           0.704209\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_NaiveBayes_Metrics.csv\n",
      "Repeat       14.500000\n",
      "Accuracy      0.547054\n",
      "Precision     0.630865\n",
      "Recall        0.703937\n",
      "F1            0.529010\n",
      "AUC           0.703937\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_metrics = []\n",
    "# Load dataset for this iteration\n",
    "data = pd.read_csv(f'{project}_processed_data.csv')\n",
    "X = data[text_col]\n",
    "y = data['class']\n",
    "\n",
    "for repeated_time in range(REPEAT):\n",
    "    \n",
    "\n",
    "    # Train-test split (70/30)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=repeated_time, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Apply TF-IDF vectorization\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
    "    X_test_tfidf = tfidf.transform(X_test).toarray()\n",
    "\n",
    "    # Train and Evaluate Naive Bayes with Cross-Validation\n",
    "    nb_clf = GaussianNB()\n",
    "    grid = GridSearchCV(nb_clf, params, cv=5, scoring='roc_auc')\n",
    "    grid.fit(X_train_tfidf, y_train)\n",
    "    best_nb = grid.best_estimator_\n",
    "    y_pred_nb = best_nb.predict(X_test_tfidf)\n",
    "    \n",
    "    nb_metrics.append({\n",
    "        \"Repeat\": repeated_time,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred_nb),\n",
    "        \"Precision\": precision_score(y_test, y_pred_nb, average='macro'),\n",
    "        \"Recall\": recall_score(y_test, y_pred_nb, average='macro'),\n",
    "        \"F1\": f1_score(y_test, y_pred_nb, average='macro'),\n",
    "        \"AUC\": auc(*roc_curve(y_test, y_pred_nb, pos_label=1)[:2])\n",
    "    })\n",
    "\n",
    "    save_model_metrics(nb_metrics, f'{project}_NaiveBayes_Metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### View progressive results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repeat</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.574944</td>\n",
       "      <td>0.633698</td>\n",
       "      <td>0.727817</td>\n",
       "      <td>0.548072</td>\n",
       "      <td>0.727817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523490</td>\n",
       "      <td>0.614797</td>\n",
       "      <td>0.680176</td>\n",
       "      <td>0.506047</td>\n",
       "      <td>0.680176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.568233</td>\n",
       "      <td>0.633268</td>\n",
       "      <td>0.723317</td>\n",
       "      <td>0.543523</td>\n",
       "      <td>0.723317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.577181</td>\n",
       "      <td>0.639039</td>\n",
       "      <td>0.696465</td>\n",
       "      <td>0.562457</td>\n",
       "      <td>0.696465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.583893</td>\n",
       "      <td>0.648970</td>\n",
       "      <td>0.728592</td>\n",
       "      <td>0.565066</td>\n",
       "      <td>0.728592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Repeat  Accuracy  Precision    Recall        F1       AUC\n",
       "0       0  0.574944   0.633698  0.727817  0.548072  0.727817\n",
       "1       1  0.523490   0.614797  0.680176  0.506047  0.680176\n",
       "2       2  0.568233   0.633268  0.723317  0.543523  0.723317\n",
       "3       3  0.577181   0.639039  0.696465  0.562457  0.696465\n",
       "4       4  0.583893   0.648970  0.728592  0.565066  0.728592"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{baseline_path}/results/{project}_NaiveBayes_Metrics.csv')\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save final results to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: tensorflow_NaiveBayes_Final_Metrics.csv\n",
      "Total_Repeats    30.000000\n",
      "Avg_Accuracy      0.547054\n",
      "Avg_Precision     0.630865\n",
      "Avg_Recall        0.703937\n",
      "Avg_F1            0.529010\n",
      "Avg_AUC           0.703937\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Calculate final averages from all repeats ===\n",
    "final_metrics = {\n",
    "    \"Total_Repeats\": REPEAT,\n",
    "    \"Avg_Accuracy\": np.mean([m[\"Accuracy\"] for m in nb_metrics]),\n",
    "    \"Avg_Precision\": np.mean([m[\"Precision\"] for m in nb_metrics]),\n",
    "    \"Avg_Recall\": np.mean([m[\"Recall\"] for m in nb_metrics]),\n",
    "    \"Avg_F1\": np.mean([m[\"F1\"] for m in nb_metrics]),\n",
    "    \"Avg_AUC\": np.mean([m[\"AUC\"] for m in nb_metrics])\n",
    "}\n",
    "\n",
    "save_model_metrics([final_metrics], f'{project}_NaiveBayes_Final_Metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load results for baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Repeats</th>\n",
       "      <th>Avg_Accuracy</th>\n",
       "      <th>Avg_Precision</th>\n",
       "      <th>Avg_Recall</th>\n",
       "      <th>Avg_F1</th>\n",
       "      <th>Avg_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>0.547054</td>\n",
       "      <td>0.630865</td>\n",
       "      <td>0.703937</td>\n",
       "      <td>0.52901</td>\n",
       "      <td>0.703937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Repeats  Avg_Accuracy  Avg_Precision  Avg_Recall   Avg_F1   Avg_AUC\n",
       "0             30      0.547054       0.630865    0.703937  0.52901  0.703937"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{baseline_path}/results/{project}_NaiveBayes_Final_Metrics.csv')\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine datasets for data leakage and overfitting and class ditribution to know what to expect when it comes to validating my results based on baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Checking Data Leakage...\n",
      "‚ö†Ô∏è 0 samples from test data are also in training data.\n",
      "‚úÖ No Data Leakage Detected.\n",
      "\n",
      "üîç Checking Overfitting...\n",
      "üìä Training Accuracy: 0.6040\n",
      "üìä Test Accuracy: 0.5302\n",
      "‚úÖ No significant overfitting detected.\n",
      "\n",
      "Class Distribution in Training Set:\n",
      "class\n",
      "0    840\n",
      "1    203\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classification Report (Naive Bayes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.44      0.61       371\n",
      "           1       0.26      0.95      0.41        76\n",
      "\n",
      "    accuracy                           0.53       447\n",
      "   macro avg       0.62      0.70      0.51       447\n",
      "weighted avg       0.85      0.53      0.58       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#check where these variables are coming from\n",
    "# For baseline Naive Bayes testing:\n",
    "check_data_leakage(X_train_tfidf, X_test_tfidf)\n",
    "check_overfitting(best_nb, X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "\n",
    "print(\"\\nClass Distribution in Training Set:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nClassification Report (Naive Bayes):\")\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform Testing with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       0.000000\n",
      "Accuracy     0.859060\n",
      "Precision    0.816919\n",
      "Recall       0.621762\n",
      "F1           0.654352\n",
      "AUC          0.621762\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       0.500000\n",
      "Accuracy     0.853468\n",
      "Precision    0.803609\n",
      "Recall       0.620231\n",
      "F1           0.650947\n",
      "AUC          0.620231\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       1.000000\n",
      "Accuracy     0.854586\n",
      "Precision    0.807650\n",
      "Recall       0.620179\n",
      "F1           0.651232\n",
      "AUC          0.620179\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       1.500000\n",
      "Accuracy     0.843400\n",
      "Precision    0.803799\n",
      "Recall       0.610256\n",
      "F1           0.635428\n",
      "AUC          0.610256\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       2.000000\n",
      "Accuracy     0.844295\n",
      "Precision    0.810726\n",
      "Recall       0.614402\n",
      "F1           0.640982\n",
      "AUC          0.614402\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       2.500000\n",
      "Accuracy     0.845638\n",
      "Precision    0.816847\n",
      "Recall       0.611533\n",
      "F1           0.637786\n",
      "AUC          0.611533\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       3.000000\n",
      "Accuracy     0.844998\n",
      "Precision    0.814245\n",
      "Recall       0.611866\n",
      "F1           0.638157\n",
      "AUC          0.611866\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       3.500000\n",
      "Accuracy     0.844799\n",
      "Precision    0.822006\n",
      "Recall       0.612281\n",
      "F1           0.638731\n",
      "AUC          0.612281\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       4.000000\n",
      "Accuracy     0.843400\n",
      "Precision    0.817552\n",
      "Recall       0.611825\n",
      "F1           0.637897\n",
      "AUC          0.611825\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       4.500000\n",
      "Accuracy     0.842953\n",
      "Precision    0.817835\n",
      "Recall       0.609615\n",
      "F1           0.634935\n",
      "AUC          0.609615\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       5.000000\n",
      "Accuracy     0.843197\n",
      "Precision    0.821138\n",
      "Recall       0.609434\n",
      "F1           0.634825\n",
      "AUC          0.609434\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       5.500000\n",
      "Accuracy     0.843400\n",
      "Precision    0.823039\n",
      "Recall       0.608102\n",
      "F1           0.633166\n",
      "AUC          0.608102\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       6.000000\n",
      "Accuracy     0.845293\n",
      "Precision    0.822589\n",
      "Recall       0.611609\n",
      "F1           0.637674\n",
      "AUC          0.611609\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       6.500000\n",
      "Accuracy     0.844839\n",
      "Precision    0.824133\n",
      "Recall       0.610400\n",
      "F1           0.636033\n",
      "AUC          0.610400\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       7.000000\n",
      "Accuracy     0.846532\n",
      "Precision    0.822972\n",
      "Recall       0.612514\n",
      "F1           0.638902\n",
      "AUC          0.612514\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       7.500000\n",
      "Accuracy     0.845498\n",
      "Precision    0.818994\n",
      "Recall       0.611607\n",
      "F1           0.637592\n",
      "AUC          0.611607\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       8.000000\n",
      "Accuracy     0.845901\n",
      "Precision    0.821093\n",
      "Recall       0.609527\n",
      "F1           0.634927\n",
      "AUC          0.609527\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       8.500000\n",
      "Accuracy     0.845389\n",
      "Precision    0.822011\n",
      "Recall       0.610732\n",
      "F1           0.636350\n",
      "AUC          0.610732\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       9.000000\n",
      "Accuracy     0.846580\n",
      "Precision    0.823959\n",
      "Recall       0.613529\n",
      "F1           0.639995\n",
      "AUC          0.613529\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       9.500000\n",
      "Accuracy     0.848434\n",
      "Precision    0.826024\n",
      "Recall       0.616639\n",
      "F1           0.644082\n",
      "AUC          0.616639\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       10.000000\n",
      "Accuracy      0.849047\n",
      "Precision     0.825123\n",
      "Recall        0.618339\n",
      "F1            0.646189\n",
      "AUC           0.618339\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       10.500000\n",
      "Accuracy      0.848892\n",
      "Precision     0.825067\n",
      "Recall        0.617201\n",
      "F1            0.644767\n",
      "AUC           0.617201\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       11.000000\n",
      "Accuracy      0.848069\n",
      "Precision     0.827848\n",
      "Recall        0.616799\n",
      "F1            0.644081\n",
      "AUC           0.616799\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       11.500000\n",
      "Accuracy      0.846849\n",
      "Precision     0.824751\n",
      "Recall        0.615400\n",
      "F1            0.642071\n",
      "AUC           0.615400\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       12.000000\n",
      "Accuracy      0.848054\n",
      "Precision     0.827802\n",
      "Recall        0.617258\n",
      "F1            0.644710\n",
      "AUC           0.617258\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       12.500000\n",
      "Accuracy      0.847703\n",
      "Precision     0.827373\n",
      "Recall        0.616730\n",
      "F1            0.644022\n",
      "AUC           0.616730\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       13.000000\n",
      "Accuracy      0.847875\n",
      "Precision     0.825680\n",
      "Recall        0.616941\n",
      "F1            0.644334\n",
      "AUC           0.616941\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       13.500000\n",
      "Accuracy      0.847236\n",
      "Precision     0.826731\n",
      "Recall        0.615674\n",
      "F1            0.642511\n",
      "AUC           0.615674\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       14.000000\n",
      "Accuracy      0.847258\n",
      "Precision     0.823550\n",
      "Recall        0.615864\n",
      "F1            0.642684\n",
      "AUC           0.615864\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_RandomForest_Metrics.csv\n",
      "Repeat       14.500000\n",
      "Accuracy      0.847278\n",
      "Precision     0.822354\n",
      "Recall        0.614628\n",
      "F1            0.641122\n",
      "AUC           0.614628\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_metrics = []\n",
    "\n",
    "# Load dataset for this iteration\n",
    "data_rf = pd.read_csv(f'{project}_processed_data.csv')\n",
    "X_rf = data_rf[text_col]\n",
    "y_rf = data_rf['class']\n",
    "\n",
    "for repeated_time in range(REPEAT):\n",
    "    \n",
    "    # Train-test split (70/30)\n",
    "    X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(\n",
    "        X_rf, y_rf, test_size=0.3, random_state=repeated_time, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Apply TF-IDF vectorization\n",
    "    tfidf_rf = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
    "    X_train_tfidf_rf = tfidf_rf.fit_transform(X_train_rf).toarray()\n",
    "    X_test_tfidf_rf = tfidf_rf.transform(X_test_rf).toarray()\n",
    "\n",
    "    # Train and Evaluate Random Forest\n",
    "    rf_clf = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "    rf_clf.fit(X_train_tfidf_rf, y_train_rf)\n",
    "    y_pred_rf = rf_clf.predict(X_test_tfidf_rf)\n",
    "\n",
    "    rf_metrics.append({\n",
    "        \"Repeat\": repeated_time,\n",
    "        \"Accuracy\": accuracy_score(y_test_rf, y_pred_rf),\n",
    "        \"Precision\": precision_score(y_test_rf, y_pred_rf, average='macro'),\n",
    "        \"Recall\": recall_score(y_test_rf, y_pred_rf, average='macro'),\n",
    "        \"F1\": f1_score(y_test_rf, y_pred_rf, average='macro'),\n",
    "        \"AUC\": auc(*roc_curve(y_test_rf, y_pred_rf, pos_label=1)[:2])\n",
    "    })\n",
    "\n",
    "    save_model_metrics(rf_metrics, f'{project}_RandomForest_Metrics.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save results to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: tensorflow_RandomForest_Final_Metrics.csv\n",
      "Total_Repeats    30.000000\n",
      "Avg_Accuracy      0.847278\n",
      "Avg_Precision     0.822354\n",
      "Avg_Recall        0.614628\n",
      "Avg_F1            0.641122\n",
      "Avg_AUC           0.614628\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Calculate final averages from all repeats ===\n",
    "final_metrics = {\n",
    "    \"Total_Repeats\": REPEAT,\n",
    "    \"Avg_Accuracy\": np.mean([m[\"Accuracy\"] for m in rf_metrics]),\n",
    "    \"Avg_Precision\": np.mean([m[\"Precision\"] for m in rf_metrics]),\n",
    "    \"Avg_Recall\": np.mean([m[\"Recall\"] for m in rf_metrics]),\n",
    "    \"Avg_F1\": np.mean([m[\"F1\"] for m in rf_metrics]),\n",
    "    \"Avg_AUC\": np.mean([m[\"AUC\"] for m in rf_metrics])\n",
    "}\n",
    "\n",
    "save_model_metrics([final_metrics], f'{project}_RandomForest_Final_Metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load results for Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Repeats</th>\n",
       "      <th>Avg_Accuracy</th>\n",
       "      <th>Avg_Precision</th>\n",
       "      <th>Avg_Recall</th>\n",
       "      <th>Avg_F1</th>\n",
       "      <th>Avg_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>0.847278</td>\n",
       "      <td>0.822354</td>\n",
       "      <td>0.614628</td>\n",
       "      <td>0.641122</td>\n",
       "      <td>0.614628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Repeats  Avg_Accuracy  Avg_Precision  Avg_Recall    Avg_F1   Avg_AUC\n",
       "0             30      0.847278       0.822354    0.614628  0.641122  0.614628"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{baseline_path}/results/{project}_RandomForest_Final_Metrics.csv')\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### My own improvement: perform testing with the hybrid Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       0.000000\n",
      "Accuracy     0.863535\n",
      "Precision    0.837338\n",
      "Recall       0.629607\n",
      "F1           0.665325\n",
      "AUC          0.629607\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       0.500000\n",
      "Accuracy     0.861298\n",
      "Precision    0.851958\n",
      "Recall       0.627569\n",
      "F1           0.662700\n",
      "AUC          0.627569\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       1.000000\n",
      "Accuracy     0.862043\n",
      "Precision    0.852127\n",
      "Recall       0.628111\n",
      "F1           0.663575\n",
      "AUC          0.628111\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       1.500000\n",
      "Accuracy     0.847315\n",
      "Precision    0.839500\n",
      "Recall       0.610476\n",
      "F1           0.635401\n",
      "AUC          0.610476\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       2.000000\n",
      "Accuracy     0.846980\n",
      "Precision    0.840776\n",
      "Recall       0.612557\n",
      "F1           0.638424\n",
      "AUC          0.612557\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       2.500000\n",
      "Accuracy     0.848248\n",
      "Precision    0.838132\n",
      "Recall       0.612707\n",
      "F1           0.639250\n",
      "AUC          0.612707\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       3.000000\n",
      "Accuracy     0.846277\n",
      "Precision    0.843747\n",
      "Recall       0.606493\n",
      "F1           0.630209\n",
      "AUC          0.606493\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       3.500000\n",
      "Accuracy     0.847036\n",
      "Precision    0.851152\n",
      "Recall       0.609861\n",
      "F1           0.634960\n",
      "AUC          0.609861\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       4.000000\n",
      "Accuracy     0.845638\n",
      "Precision    0.852194\n",
      "Recall       0.607446\n",
      "F1           0.631519\n",
      "AUC          0.607446\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       4.500000\n",
      "Accuracy     0.845190\n",
      "Precision    0.851136\n",
      "Recall       0.605812\n",
      "F1           0.629413\n",
      "AUC          0.605812\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       5.000000\n",
      "Accuracy     0.844011\n",
      "Precision    0.850512\n",
      "Recall       0.602358\n",
      "F1           0.624379\n",
      "AUC          0.602358\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       5.500000\n",
      "Accuracy     0.843960\n",
      "Precision    0.851187\n",
      "Recall       0.600714\n",
      "F1           0.622255\n",
      "AUC          0.600714\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       6.000000\n",
      "Accuracy     0.845465\n",
      "Precision    0.851903\n",
      "Recall       0.601765\n",
      "F1           0.624182\n",
      "AUC          0.601765\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       6.500000\n",
      "Accuracy     0.845318\n",
      "Precision    0.854753\n",
      "Recall       0.601457\n",
      "F1           0.623823\n",
      "AUC          0.601457\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       7.000000\n",
      "Accuracy     0.847576\n",
      "Precision    0.853370\n",
      "Recall       0.605645\n",
      "F1           0.629315\n",
      "AUC          0.605645\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       7.500000\n",
      "Accuracy     0.847315\n",
      "Precision    0.852450\n",
      "Recall       0.605963\n",
      "F1           0.629806\n",
      "AUC          0.605963\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       8.000000\n",
      "Accuracy     0.848796\n",
      "Precision    0.853836\n",
      "Recall       0.608006\n",
      "F1           0.632870\n",
      "AUC          0.608006\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       8.500000\n",
      "Accuracy     0.847999\n",
      "Precision    0.854067\n",
      "Recall       0.608567\n",
      "F1           0.633480\n",
      "AUC          0.608567\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       9.000000\n",
      "Accuracy     0.849641\n",
      "Precision    0.856805\n",
      "Recall       0.612336\n",
      "F1           0.638484\n",
      "AUC          0.612336\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       9.500000\n",
      "Accuracy     0.851342\n",
      "Precision    0.859073\n",
      "Recall       0.614693\n",
      "F1           0.641922\n",
      "AUC          0.614693\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       10.000000\n",
      "Accuracy      0.852029\n",
      "Precision     0.859710\n",
      "Recall        0.615668\n",
      "F1            0.643429\n",
      "AUC           0.615668\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       10.500000\n",
      "Accuracy      0.852247\n",
      "Precision     0.859853\n",
      "Recall        0.615836\n",
      "F1            0.643809\n",
      "AUC           0.615836\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       11.000000\n",
      "Accuracy      0.851376\n",
      "Precision     0.861207\n",
      "Recall        0.615720\n",
      "F1            0.643491\n",
      "AUC           0.615720\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       11.500000\n",
      "Accuracy      0.850858\n",
      "Precision     0.860420\n",
      "Recall        0.615757\n",
      "F1            0.643487\n",
      "AUC           0.615757\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       12.000000\n",
      "Accuracy      0.851812\n",
      "Precision     0.862597\n",
      "Recall        0.617148\n",
      "F1            0.645560\n",
      "AUC           0.617148\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       12.500000\n",
      "Accuracy      0.851403\n",
      "Precision     0.862757\n",
      "Recall        0.616338\n",
      "F1            0.644458\n",
      "AUC           0.616338\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       13.000000\n",
      "Accuracy      0.852266\n",
      "Precision     0.862330\n",
      "Recall        0.618375\n",
      "F1            0.647041\n",
      "AUC           0.618375\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       13.500000\n",
      "Accuracy      0.851870\n",
      "Precision     0.863426\n",
      "Recall        0.617910\n",
      "F1            0.646400\n",
      "AUC           0.617910\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       14.000000\n",
      "Accuracy      0.852580\n",
      "Precision     0.863313\n",
      "Recall        0.618716\n",
      "F1            0.647623\n",
      "AUC           0.618716\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Saved: tensorflow_HybridModel_Metrics.csv\n",
      "Repeat       14.500000\n",
      "Accuracy      0.852796\n",
      "Precision     0.863544\n",
      "Recall        0.617959\n",
      "F1            0.646768\n",
      "AUC           0.617959\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hybrid_metrics = []\n",
    "# Load dataset for this iteration\n",
    "data = pd.read_csv(f'{project}_processed_data.csv')\n",
    "X_hybrid = data[text_col]\n",
    "y_hybrid = data['class']\n",
    "\n",
    "for repeated_time in range(REPEAT):\n",
    "    \n",
    "\n",
    "    X_train_hybrid, X_test_hybrid, y_train_hybrid, y_test_hybrid = train_test_split(\n",
    "        X_hybrid, y_hybrid, test_size=0.3, random_state=repeated_time, shuffle=True\n",
    "    )\n",
    "\n",
    "    tfidf_hybrid = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
    "    X_train_tfidf_hybrid = tfidf_hybrid.fit_transform(X_train_hybrid).toarray()\n",
    "    X_test_tfidf_hybrid = tfidf_hybrid.transform(X_test_hybrid).toarray()\n",
    "\n",
    "    rf_clf_hybrid = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "    rf_clf_hybrid.fit(X_train_tfidf_hybrid, y_train_hybrid)\n",
    "\n",
    "    logreg_clf_hybrid = LogisticRegression(max_iter=2000)\n",
    "    voting_clf_hybrid = VotingClassifier(estimators=[('rf', rf_clf_hybrid), ('logreg', logreg_clf_hybrid)], voting='soft')\n",
    "    voting_clf_hybrid.fit(X_train_tfidf_hybrid, y_train_hybrid)\n",
    "\n",
    "    y_pred_hybrid = voting_clf_hybrid.predict(X_test_tfidf_hybrid)\n",
    "\n",
    "    hybrid_metrics.append({\n",
    "        \"Repeat\": repeated_time,\n",
    "        \"Accuracy\": accuracy_score(y_test_hybrid, y_pred_hybrid),\n",
    "        \"Precision\": precision_score(y_test_hybrid, y_pred_hybrid, average='macro'),\n",
    "        \"Recall\": recall_score(y_test_hybrid, y_pred_hybrid, average='macro'),\n",
    "        \"F1\": f1_score(y_test_hybrid, y_pred_hybrid, average='macro'),\n",
    "        \"AUC\": auc(*roc_curve(y_test_hybrid, y_pred_hybrid, pos_label=1)[:2])\n",
    "    })\n",
    "\n",
    "    save_model_metrics(hybrid_metrics, f'{project}_HybridModel_Metrics.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save results to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: tensorflow_HybridModel_Final_Metrics.csv\n",
      "Total_Repeats    30.000000\n",
      "Avg_Accuracy      0.852796\n",
      "Avg_Precision     0.863544\n",
      "Avg_Recall        0.617959\n",
      "Avg_F1            0.646768\n",
      "Avg_AUC           0.617959\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Calculate final averages from all repeats ===\n",
    "final_metrics = {\n",
    "    \"Total_Repeats\": REPEAT,\n",
    "    \"Avg_Accuracy\": np.mean([m[\"Accuracy\"] for m in hybrid_metrics]),\n",
    "    \"Avg_Precision\": np.mean([m[\"Precision\"] for m in hybrid_metrics]),\n",
    "    \"Avg_Recall\": np.mean([m[\"Recall\"] for m in hybrid_metrics]),\n",
    "    \"Avg_F1\": np.mean([m[\"F1\"] for m in hybrid_metrics]),\n",
    "    \"Avg_AUC\": np.mean([m[\"AUC\"] for m in hybrid_metrics])\n",
    "}\n",
    "\n",
    "save_model_metrics([final_metrics], f'{project}_HybridModel_Final_Metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load results for Hybrid Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Repeats</th>\n",
       "      <th>Avg_Accuracy</th>\n",
       "      <th>Avg_Precision</th>\n",
       "      <th>Avg_Recall</th>\n",
       "      <th>Avg_F1</th>\n",
       "      <th>Avg_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>0.852796</td>\n",
       "      <td>0.863544</td>\n",
       "      <td>0.617959</td>\n",
       "      <td>0.646768</td>\n",
       "      <td>0.617959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Repeats  Avg_Accuracy  Avg_Precision  Avg_Recall    Avg_F1   Avg_AUC\n",
       "0             30      0.852796       0.863544    0.617959  0.646768  0.617959"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{baseline_path}/results/{project}_HybridModel_Final_Metrics.csv')\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Validate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now that the training has been complete with the baselineto be able to compare with my own improvements. \n",
    "###### I want to ensure my results can be trusted so, FOR THE HYBRID MODEL, I will test on holdout data, check for data leakage an overfitting. I will also check the class distribution of the training set and perfrom SMOTE to Balance the dataset and retest witht the hybrid model, to see if there any differences in results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Hybrid Model on Holdout Data ---Shoukld this repeat 30 times???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Holdout Set Performance (Hybrid Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Non-Bug       0.80      1.00      0.89       119\n",
      "         Bug       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.80       149\n",
      "   macro avg       0.40      0.50      0.44       149\n",
      "weighted avg       0.64      0.80      0.71       149\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "###0 IS A NONBUG, SO IT IS WHAT SHOULD BE PRE4DICTED AS NONBUG\n",
    "\n",
    "# Define function to test trained hybrid model on holdout set\n",
    "def test_on_holdout_hybrid(model):\n",
    "    holdout_data_hybrid = pd.read_csv(f'{project}_processed_data_holdout.csv')\n",
    "    holdout_text_hybrid = holdout_data_hybrid[text_col]\n",
    "    holdout_labels_hybrid = holdout_data_hybrid['class']\n",
    "\n",
    "    tfidf_hybrid_holdout = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
    "    X_holdout_hybrid = tfidf_hybrid_holdout.fit_transform(holdout_text_hybrid).toarray()\n",
    "\n",
    "    holdout_preds_hybrid = model.predict(X_holdout_hybrid)\n",
    "    print(\"\\nüîç Holdout Set Performance (Hybrid Model):\")\n",
    "    print(classification_report(holdout_labels_hybrid, holdout_preds_hybrid, target_names=['Non-Bug', 'Bug']))\n",
    "\n",
    "    # Load full processed dataset\n",
    "data = pd.read_csv(f'{project}_processed_data.csv')\n",
    "\n",
    "# Create holdout split (90% train/test, 10% holdout)\n",
    "train_test_data, holdout_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Save to CSV for consistent usage across notebooks\n",
    "train_test_data.to_csv(f'{project}_processed_train_test_data_holdout.csv', index=False)\n",
    "holdout_data.to_csv(f'{project}_processed_data_holdout.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hybrid_holdout_metrics = []\n",
    "\n",
    "# Load 90% dataset for training/testing splits\n",
    "data_hybrid_holdout = pd.read_csv(f'{project}_processed_train_test_data_holdout.csv')\n",
    "X_hybrid_holdout = data_hybrid_holdout[text_col]\n",
    "y_hybrid_holdout = data_hybrid_holdout['class']\n",
    "\n",
    "for repeated_time in range(REPEAT):\n",
    "    # Split into 70/30\n",
    "    X_train_hybrid, X_test_hybrid, y_train_hybrid, y_test_hybrid = train_test_split(\n",
    "        X_hybrid_holdout, y_hybrid_holdout, test_size=0.3, random_state=repeated_time, shuffle=True\n",
    "    )\n",
    "\n",
    "    # TF-IDF\n",
    "    tfidf_hybrid = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
    "    X_train_tfidf_hybrid = tfidf_hybrid.fit_transform(X_train_hybrid).toarray()\n",
    "    X_test_tfidf_hybrid = tfidf_hybrid.transform(X_test_hybrid).toarray()\n",
    "\n",
    "    # Random Forest\n",
    "    rf_clf_hybrid = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "    rf_clf_hybrid.fit(X_train_tfidf_hybrid, y_train_hybrid)\n",
    "\n",
    "    # Hybrid Model: Random Forest + Logistic Regression\n",
    "    logreg_clf_hybrid = LogisticRegression(max_iter=2000)\n",
    "    voting_clf_hybrid = VotingClassifier(estimators=[\n",
    "        ('rf', rf_clf_hybrid), \n",
    "        ('logreg', logreg_clf_hybrid)\n",
    "    ], voting='soft')\n",
    "    voting_clf_hybrid.fit(X_train_tfidf_hybrid, y_train_hybrid)\n",
    "    y_pred_hybrid = voting_clf_hybrid.predict(X_test_tfidf_hybrid)\n",
    "\n",
    "    # Save metrics for each repeat\n",
    "    hybrid_holdout_metrics.append({\n",
    "        \"Repeat\": repeated_time,\n",
    "        \"Accuracy\": accuracy_score(y_test_hybrid, y_pred_hybrid),\n",
    "        \"Precision\": precision_score(y_test_hybrid, y_pred_hybrid, average='macro'),\n",
    "        \"Recall\": recall_score(y_test_hybrid, y_pred_hybrid, average='macro'),\n",
    "        \"F1\": f1_score(y_test_hybrid, y_pred_hybrid, average='macro'),\n",
    "        \"AUC\": auc(*roc_curve(y_test_hybrid, y_pred_hybrid, pos_label=1)[:2])\n",
    "    })\n",
    "\n",
    "# Save all repeated metrics to CSV\n",
    "#save_model_metrics(hybrid_holdout_metrics, f'{project}_HybridModel_Holdout_Metrics.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on true holdout portion\n",
    "test_on_holdout_hybrid(voting_clf_hybrid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save results to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load results for test on holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"processed_data_holdout.csv\")\n",
    "#df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for data leakage and overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Checking Data Leakage...\n",
      "‚ö†Ô∏è 0 samples from test data are also in training data.\n",
      "‚úÖ No Data Leakage Detected.\n",
      "\n",
      "üîç Checking Overfitting...\n",
      "üìä Training Accuracy: 0.9648\n",
      "üìä Test Accuracy: 0.8337\n",
      "‚ùå Possible Overfitting: Model performs much better on training data.\n"
     ]
    }
   ],
   "source": [
    "#check where these variables are coming from\n",
    "check_data_leakage(X_train_tfidf_hybrid, X_test_tfidf_hybrid)\n",
    "check_overfitting(voting_clf_hybrid, X_train_tfidf_hybrid, y_train_hybrid, X_test_tfidf_hybrid, y_test_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check class distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution in Training Set:\n",
      "class\n",
      "0    768\n",
      "1    170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       324\n",
      "           1       0.93      0.16      0.28        79\n",
      "\n",
      "    accuracy                           0.83       403\n",
      "   macro avg       0.88      0.58      0.59       403\n",
      "weighted avg       0.85      0.83      0.78       403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClass Distribution in Training Set:\")\n",
    "print(y_train_hybrid.value_counts())\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_hybrid, y_pred_hybrid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform Smote to Balance Dataset and Test Hybrid Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: tensorflow_SMOTE_HybridModel_Metrics.csv\n",
      "Repeat       14.500000\n",
      "Accuracy      0.876883\n",
      "Precision     0.797945\n",
      "Recall        0.796757\n",
      "F1            0.795677\n",
      "AUC           0.796757\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote_hybrid_metrics = []\n",
    "\n",
    "# Load dataset for SMOTE-based training\n",
    "data_smote_hybrid = pd.read_csv(f'{project}_processed_data.csv')\n",
    "X_smote_hybrid = data_smote_hybrid[text_col]\n",
    "y_smote_hybrid = data_smote_hybrid['class']\n",
    "\n",
    "for repeated_time in range(REPEAT):\n",
    "    # Train-test split (70/30)\n",
    "    X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(\n",
    "        X_smote_hybrid, y_smote_hybrid, test_size=0.3, random_state=repeated_time, shuffle=True\n",
    "    )\n",
    "\n",
    "    # TF-IDF vectorization\n",
    "    tfidf_smote = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
    "    X_train_tfidf_smote = tfidf_smote.fit_transform(X_train_smote).toarray()\n",
    "    X_test_tfidf_smote = tfidf_smote.transform(X_test_smote).toarray()\n",
    "\n",
    "    # Train Hybrid Model\n",
    "    rf_clf_smote = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "    logreg_clf_smote = LogisticRegression(max_iter=2000)\n",
    "    hybrid_clf_smote = VotingClassifier(\n",
    "        estimators=[('rf', rf_clf_smote), ('logreg', logreg_clf_smote)],\n",
    "        voting='soft'\n",
    "    )\n",
    "\n",
    "    # Apply SMOTE to balance training data\n",
    "    smote = SMOTE()\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_tfidf_smote, y_train_smote)\n",
    "\n",
    "    # Train on balanced data\n",
    "    hybrid_clf_smote.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "    # Predict on original (unbalanced) test set\n",
    "    y_pred_smote_hybrid = hybrid_clf_smote.predict(X_test_tfidf_smote)\n",
    "\n",
    "    # Collect metrics\n",
    "    smote_hybrid_metrics.append({\n",
    "        \"Repeat\": repeated_time,\n",
    "        \"Accuracy\": accuracy_score(y_test_smote, y_pred_smote_hybrid),\n",
    "        \"Precision\": precision_score(y_test_smote, y_pred_smote_hybrid, average='macro'),\n",
    "        \"Recall\": recall_score(y_test_smote, y_pred_smote_hybrid, average='macro'),\n",
    "        \"F1\": f1_score(y_test_smote, y_pred_smote_hybrid, average='macro'),\n",
    "        \"AUC\": auc(*roc_curve(y_test_smote, y_pred_smote_hybrid, pos_label=1)[:2])\n",
    "    })\n",
    "\n",
    "# Save metrics after all repeats\n",
    "save_model_metrics(smote_hybrid_metrics, f'{project}_SMOTE_HybridModel_Metrics.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save and load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: tensorflow_SMOTE_HybridModel_Final_Metrics.csv\n",
      "Total_Repeats    30.000000\n",
      "Avg_Accuracy      0.878896\n",
      "Avg_Precision     0.801349\n",
      "Avg_Recall        0.799384\n",
      "Avg_F1            0.798755\n",
      "Avg_AUC           0.799384\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Calculate final averages from all repeats ===\n",
    "final_metrics = {\n",
    "    \"Total_Repeats\": REPEAT,\n",
    "    \"Avg_Accuracy\": np.mean([m[\"Accuracy\"] for m in smote_hybrid_metrics]),\n",
    "    \"Avg_Precision\": np.mean([m[\"Precision\"] for m in smote_hybrid_metrics]),\n",
    "    \"Avg_Recall\": np.mean([m[\"Recall\"] for m in smote_hybrid_metrics]),\n",
    "    \"Avg_F1\": np.mean([m[\"F1\"] for m in smote_hybrid_metrics]),\n",
    "    \"Avg_AUC\": np.mean([m[\"AUC\"] for m in smote_hybrid_metrics])\n",
    "}\n",
    "\n",
    "save_model_metrics([final_metrics], f'{project}_SMOTE_HybridModel_Final_Metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Repeats</th>\n",
       "      <th>Avg_Accuracy</th>\n",
       "      <th>Avg_Precision</th>\n",
       "      <th>Avg_Recall</th>\n",
       "      <th>Avg_F1</th>\n",
       "      <th>Avg_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>0.878896</td>\n",
       "      <td>0.801349</td>\n",
       "      <td>0.799384</td>\n",
       "      <td>0.798755</td>\n",
       "      <td>0.799384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Repeats  Avg_Accuracy  Avg_Precision  Avg_Recall    Avg_F1   Avg_AUC\n",
       "0             30      0.878896       0.801349    0.799384  0.798755  0.799384"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{baseline_path}/results/{project}_SMOTE_HybridModel_Final_Metrics.csv')\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Checking Data Leakage...\n",
      "‚ö†Ô∏è 0 samples from test data are also in training data.\n",
      "‚úÖ No Data Leakage Detected.\n",
      "\n",
      "üîç Checking Overfitting...\n",
      "üìä Training Accuracy: 0.9952\n",
      "üìä Test Accuracy: 0.8680\n",
      "‚ùå Possible Overfitting: Model performs much better on training data.\n",
      "\n",
      "Original Class Distribution in Training Set (Before SMOTE):\n",
      "class\n",
      "0    840\n",
      "1    203\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced Class Distribution After SMOTE:\n",
      "class\n",
      "0    840\n",
      "1    840\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classification Report (SMOTE Hybrid Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       371\n",
      "           1       0.62      0.57      0.59        76\n",
      "\n",
      "    accuracy                           0.87       447\n",
      "   macro avg       0.77      0.75      0.76       447\n",
      "weighted avg       0.86      0.87      0.87       447\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ‚úÖ Data Leakage Check (only makes sense for original training data before SMOTE)\n",
    "check_data_leakage(X_train_tfidf_smote, X_test_tfidf_smote)\n",
    "\n",
    "# ‚úÖ Overfitting Check (use SMOTE-balanced training data and unbalanced test data)\n",
    "check_overfitting(hybrid_clf_smote, X_train_balanced, y_train_balanced, X_test_tfidf_smote, y_test_smote)\n",
    "\n",
    "# ‚úÖ Class Distribution\n",
    "print(\"\\nOriginal Class Distribution in Training Set (Before SMOTE):\")\n",
    "print(y_train_smote.value_counts())\n",
    "\n",
    "print(\"\\nBalanced Class Distribution After SMOTE:\")\n",
    "print(pd.Series(y_train_balanced).value_counts())\n",
    "\n",
    "# ‚úÖ Classification Report\n",
    "print(\"\\nClassification Report (SMOTE Hybrid Model):\")\n",
    "print(classification_report(y_test_smote, y_pred_smote_hybrid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
